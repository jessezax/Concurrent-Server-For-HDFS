# Concurrent-Server-For-HDFS
    设计思想
近年来，现代大规模数据处理应用使用的领域越来越广，而传统的面向大数据系统提供有效高速的数据传输方面由于一定方面的限制，性能上并不是很理想，在满足现代大规模数据处理应用的需求方面越来越捉襟见肘。而新型的具有可扩展性的并行数据传输软件则出现有望解决这一问题。
数据传输是大数据系统中最常见的部分，如在Storm中对Spouts的数据传输、在Kafka中对topic的数据传输、在Hbase中对表的数据插入。其中，Storm是一套专门用于事件流处理的分布式计算框架。Hbase是一个分布式的、面向列的适合于非结构化数据存储的开源数据库。Kafka是一种高吞吐量的分布式发布订阅消息系统，它可以处理消费者规模的网站中的所有动作流数据。
在对这些大数据系统进行数据输入的流程中，即便在后续流程中大数据系统有着较高的处理数据能力，但往往正是数据源低下的吞吐率影响了整个系统最终的处理效率。因此数据源对大数据系统的输入，成了整个系统吞吐率的瓶颈。近年来，高效的数据传输已经成为支持大数据系统实现高效吞吐率的一个至关重要地组成部分，这就需要一套复杂的基础设施对其提供支持。针对数据数据传输，提供一种高吞吐、高容错同时保证的存储软件也同样显得重要。基于此，我们选择将HDFS（Hadoop分布式文件系统）作为数据的存储点。
因此，面向大数据系统的高容错并行数据传输软件(Concurrent Server For HDFS，以下简称CSFH)旨在设计出一款对HDFS中文件进行数据处理且支持多个节点服务器并发高效地将处理数据提供给Storm、HBase、Kafka等大数据系统的软件。
CSFH主要包含一个协调器和多个节点服务器。协调器结合HDFS来对文件数据进行高效的管理。多个节点服务器则负责将数据并行传输到大数据系统之中。其中，HDFS具有能支持超大文件的处理，并可以运行在大规模廉价商用机器集群上的优势。近年来，HDFS已经成为大数据磁盘存储的主流，用于海量日志类大文件的存储与管理。
在体现可扩展性和数据的高速传输下，数据的正确性也显得尤为重要。为了保证数据传输的正确性，在CSFH的协调器中进一步设计了快速轻量的校验方法来对多节点服务器的传输数据进行校验。
		基本功能
为了解决当前面向大数据系统间数据传输没有充分发挥分布式系统的优点，无法高效并行快速读取数据的问题，CSFH提供面向Kafka、Storm、Hbase并行化的数据传输方式，提升面向大数据系统的整体吞吐能力。相比于传统的数据传输方式，CSFH可以达到节点服务器可扩展的向大数据系统并行传输数据。
	
	（1）多个节点服务器并行向HBase提供已格式化好的数据。数据内容具体：行键为文件名加上下载行数，而列族包含每行数据的下载时间，数据大小以及数据内容。
	（2）多个节点服务器并行向Kafka提供已格式化好的数据。将一份数据（数据内容和下载数据的时间戳）并行提供给Kafka中的topic，方便下一步的Comsummer进行消费信息。
	（3）多个节点服务器并行向Storm提供已格式化好的数据。将一份数据（数据内容和下载数据的时间戳）并行提供给Storm中的Spouts，方便其进行下一步的bolts运算。
	（4）为保证时序性，在协调器中，也为HDFS中的数据增加了时间戳的处理。
	（5）分支服务器与协调器间的并发数据传输功能：CSFH并发协调器接受高并发的分支服务器登录，并可以接受多个分支服务器（最多为系统限制进程数）的并行数据传输任务。在整个传输流程中，协调器和分支服务器使用MD5校验来对传输的数据进行高效的校验。分支服务器具备主动中断功能，能够及时中断数据传输，协调器同时也会中断传输。当分支服务器重连时，可以在断点处继续进行下载。每次传输数据时，分支服务器需将已有数据（并未下载完毕）的与协调器中数据进行一致性判定，避免将整体数据进行重传。同时，对于不断增量更新的数据，即不断在文件最后进行续写更新的数据也仍然能获取，
	（6）协调器的公平资源分配功能：当服务器负载到了限度（如开启到最大进程），还有新的分支服务器需要加入时，可能导致资源无法分配，或资源分配不公平的问题。CSFH引入Lru公平机制，即找到不再需要服务的分支服务器，将其踢出，使子进程服务新的分支服务器，以此达到资源的公平分配。
